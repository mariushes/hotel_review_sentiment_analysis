{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"name":"Pre_trained_dataset.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"Qum39ZQ60fqy","colab_type":"text"},"source":["# Pre-trained Dataset with Doc2Vec\n","### 1. Data import\n","### 2. Create a wordlist of all inputs\n","### 3. Load the model and the keyedVector\n","### 4. Compares the words of the embedding with the words of our text\n","### 5. Find the words, that appear in our text, but not in the embedding-model\n","### 6. Test if different punctuations are contained in the embedding-model\n","### 7. Print the most frequent words to get insides \n","### 8. Infer vectors\n","### 9. Create dataframe, add score and save output"]},{"cell_type":"markdown","metadata":{"id":"nBXO4Ynh0fq1","colab_type":"text"},"source":["**1. Data import**\n"]},{"cell_type":"code","metadata":{"id":"hLzaVNAlbpf4","colab_type":"code","outputId":"f014f511-2c5a-4696-8e7c-cb862c6588ef","executionInfo":{"status":"ok","timestamp":1589911193474,"user_tz":-120,"elapsed":31654,"user":{"displayName":"Len nard","photoUrl":"","userId":"16741936559046640611"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZhMlkgClabLg","colab_type":"code","colab":{}},"source":["# CSVLInk = r'/content/drive/My Drive/test2_token_excludeSpecPuct.csv'\n","CSVLInk = r'/content/drive/My Drive/tokenTrue_remStpwrdsTrue_stemmTrue_lemmatizeFalse_nGramFalse_nGram_length2.csv'\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WgZxuNLBC0Bi","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import io\n","import time\n","\n","hotelData = pd.read_csv(CSVLInk) \n","review = hotelData[\"Review\"].apply(lambda row: row.strip(\"']['\").split(\"', '\"))\n","score = hotelData[\"Reviewer_Score\"]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uSmCFn-p0frI","colab_type":"text"},"source":["**2. Create a wordlist of all inputs**"]},{"cell_type":"code","metadata":{"id":"XLpH1qBJ0frL","colab_type":"code","colab":{}},"source":["# Source: https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings/comments\n","from tqdm import tqdm\n","tqdm.pandas()\n","\n","def build_vocab(sentences, verbose =  True):\n","    \"\"\"\n","    :param sentences: list of list of words\n","    :return: dictionary of words and their count\n","    \"\"\"\n","    vocab = {}\n","    for sentence in tqdm(sentences, disable = (not verbose)):\n","        for word in sentence:\n","            try:\n","                vocab[word] += 1\n","            except KeyError:\n","                vocab[word] = 1\n","    return vocab"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KBdPAuq70frW","colab_type":"code","outputId":"95805961-f0e3-42d1-82e7-250ce9ad9d52","executionInfo":{"status":"ok","timestamp":1589911250516,"user_tz":-120,"elapsed":3152,"user":{"displayName":"Len nard","photoUrl":"","userId":"16741936559046640611"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["vocab = build_vocab(review)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 515738/515738 [00:02<00:00, 256631.88it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"YG5RLyqZ0frf","colab_type":"text"},"source":["**3. Load the model and the keyedVector**"]},{"cell_type":"code","metadata":{"id":"5oPgHaqkoEF9","colab_type":"code","colab":{}},"source":["modelLNK = r'/content/drive/My Drive/enwiki_dbow/doc2vec.bin'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4qS3bne20frg","colab_type":"code","outputId":"552eb309-4fd3-4458-ec86-60bc21b3d57c","executionInfo":{"status":"ok","timestamp":1589911335235,"user_tz":-120,"elapsed":59091,"user":{"displayName":"Len nard","photoUrl":"","userId":"16741936559046640611"}},"colab":{"base_uri":"https://localhost:8080/","height":166}},"source":["from gensim.test.utils import common_texts\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","from gensim.test.utils import get_tmpfile\n","from gensim.models import KeyedVectors\n","import gensim.models as g\n","import time\n","\n","firstTime = time.time()\n","#load model\n","\n","model = g.Doc2Vec.load(modelLNK)\n","\n","embeddings_index = model.wv\n","\n","print (\"--- %s seconds ---\" % round(time.time()-firstTime,4))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["--- 57.7371 seconds ---\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/models/doc2vec.py:566: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\n","  warnings.warn(\"The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\")\n","/usr/local/lib/python3.6/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n","  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Dj53Uiqt0frq","colab_type":"text"},"source":["**4. Compares the words of the embedding with the words of our text**"]},{"cell_type":"code","metadata":{"id":"8TtkFj5i0frr","colab_type":"code","colab":{}},"source":["# source https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings/comments\n","import operator \n","\n","def check_coverage(vocab,embeddings_index):\n","    a = {}\n","    oov = {}\n","    k = 0\n","    i = 0\n","    for word in tqdm(vocab):\n","        try:\n","            a[word] = embeddings_index[word]\n","            k += vocab[word]\n","        except:\n","\n","            oov[word] = vocab[word]\n","            i += vocab[word]\n","            pass\n","    print(\"\\n\")\n","    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n","    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n","    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n","\n","    return sorted_x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NwXRY-0s0fr1","colab_type":"code","outputId":"ec41aba3-21e9-4836-94ed-36d32321161c","executionInfo":{"status":"ok","timestamp":1588933713176,"user_tz":-120,"elapsed":663,"user":{"displayName":"Len nard","photoUrl":"","userId":"16741936559046640611"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["oov = check_coverage(vocab,embeddings_index)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 81291/81291 [00:00<00:00, 330542.77it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","Found embeddings for 54.03% of vocab\n","Found embeddings for  99.39% of all text\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"FPSbI8sov8VR","colab_type":"text"},"source":["**5. Find the words, that appear in our text, but not in the embedding-model**"]},{"cell_type":"code","metadata":{"id":"oVrLUs190fsM","colab_type":"code","outputId":"daf3c2be-9942-4171-d155-89068ff05ebf","executionInfo":{"status":"ok","timestamp":1588933935523,"user_tz":-120,"elapsed":4031,"user":{"displayName":"Len nard","photoUrl":"","userId":"16741936559046640611"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["oov[:10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('wouldn', 3350),\n"," ('helpfull', 2309),\n"," ('confortable', 1218),\n"," ('hadn', 1163),\n"," ('wasnt', 1141),\n"," ('spotlessly', 1059),\n"," ('couldnt', 814),\n"," ('30am', 803),\n"," ('30pm', 554),\n"," ('coffe', 536)]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"VbJmmq-bwFXX","colab_type":"text"},"source":["**6. Test if different punctuations are contained in the embedding-model**"]},{"cell_type":"code","metadata":{"id":"ChPN3VlaGlb2","colab_type":"code","outputId":"fb1e1ba8-369c-4857-d276-5c22cf695258","executionInfo":{"status":"ok","timestamp":1589911393239,"user_tz":-120,"elapsed":1065,"user":{"displayName":"Len nard","photoUrl":"","userId":"16741936559046640611"}},"colab":{"base_uri":"https://localhost:8080/","height":682}},"source":["import string\n","punctuationList = string.punctuation \n","punctuationList = punctuationList+\"’\" + \"”\" + \"“\"+\"—\"\n","for punctuation in punctuationList:\n","    print(punctuation, \" in the embedding: \",punctuation in vocab)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["!  in the embedding:  False\n","\"  in the embedding:  False\n","#  in the embedding:  False\n","$  in the embedding:  False\n","%  in the embedding:  False\n","&  in the embedding:  False\n","'  in the embedding:  False\n","(  in the embedding:  False\n",")  in the embedding:  False\n","*  in the embedding:  False\n","+  in the embedding:  False\n",",  in the embedding:  False\n","-  in the embedding:  False\n",".  in the embedding:  False\n","/  in the embedding:  False\n",":  in the embedding:  False\n",";  in the embedding:  False\n","<  in the embedding:  False\n","=  in the embedding:  False\n",">  in the embedding:  False\n","?  in the embedding:  False\n","@  in the embedding:  False\n","[  in the embedding:  False\n","\\  in the embedding:  False\n","]  in the embedding:  False\n","^  in the embedding:  False\n","_  in the embedding:  False\n","`  in the embedding:  False\n","{  in the embedding:  False\n","|  in the embedding:  False\n","}  in the embedding:  False\n","~  in the embedding:  False\n","’  in the embedding:  False\n","”  in the embedding:  False\n","“  in the embedding:  False\n","—  in the embedding:  False\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EFm_Kn9m0fsU","colab_type":"code","outputId":"2e4d2779-6e11-4d5e-84a6-03d730fbff96","executionInfo":{"status":"ok","timestamp":1588600112799,"user_tz":-120,"elapsed":968,"user":{"displayName":"Len nard","photoUrl":"","userId":"16741936559046640611"}},"colab":{"base_uri":"https://localhost:8080/","height":671}},"source":["import string\n","punctuationList = string.punctuation \n","punctuationList = punctuationList+\"’\" + \"”\" + \"“\"+\"—\"\n","for punctuation in punctuationList:\n","    print(punctuation, \" in the embedding: \",punctuation in embeddings_index)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["!  in the embedding:  True\n","\"  in the embedding:  False\n","#  in the embedding:  True\n","$  in the embedding:  True\n","%  in the embedding:  True\n","&  in the embedding:  True\n","'  in the embedding:  True\n","(  in the embedding:  False\n",")  in the embedding:  False\n","*  in the embedding:  True\n","+  in the embedding:  True\n",",  in the embedding:  True\n","-  in the embedding:  True\n",".  in the embedding:  True\n","/  in the embedding:  True\n",":  in the embedding:  True\n",";  in the embedding:  True\n","<  in the embedding:  True\n","=  in the embedding:  True\n",">  in the embedding:  True\n","?  in the embedding:  True\n","@  in the embedding:  True\n","[  in the embedding:  False\n","\\  in the embedding:  True\n","]  in the embedding:  False\n","^  in the embedding:  True\n","_  in the embedding:  True\n","`  in the embedding:  True\n","{  in the embedding:  False\n","|  in the embedding:  True\n","}  in the embedding:  False\n","~  in the embedding:  True\n","’  in the embedding:  False\n","”  in the embedding:  False\n","“  in the embedding:  False\n","—  in the embedding:  False\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zc4yBobXwSJW","colab_type":"text"},"source":["**7. Print the most frequent words to get insides**"]},{"cell_type":"code","metadata":{"id":"YXXtGkxl0fsd","colab_type":"code","outputId":"97bbdf65-2828-4502-df16-db23511322f9","executionInfo":{"status":"ok","timestamp":1588600117272,"user_tz":-120,"elapsed":806,"user":{"displayName":"Len nard","photoUrl":"","userId":"16741936559046640611"}},"colab":{"base_uri":"https://localhost:8080/","height":380}},"source":["for i in range(20):\n","    print(embeddings_index.index2entity[i])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["the\n",",\n",".\n","of\n","and\n","in\n","a\n","to\n","was\n","''\n","``\n","is\n","for\n","-rrb-\n","-lrb-\n","as\n","on\n","with\n","by\n","he\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JwvBoJvbwbQn","colab_type":"text"},"source":["**8. Infer vectors**"]},{"cell_type":"code","metadata":{"id":"qd2NpfWu0fss","colab_type":"code","outputId":"db9e9778-a33d-410a-ac0a-03d323267e55","executionInfo":{"status":"ok","timestamp":1588695181035,"user_tz":-120,"elapsed":44940,"user":{"displayName":"Len nard","photoUrl":"","userId":"16741936559046640611"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["firstTime = time.time()\n","\n","#inference hyper-parameters # Sorce Paper \n","start_alpha=0.01\n","min_alpha = 0.0001\n","infer_epoch=750\n","\n","vectors = []\n","for text in review.tolist():\n","    vectors.append(model.infer_vector(text, alpha= start_alpha, min_alpha= min_alpha, epochs= infer_epoch))\n","print (\"--- %s seconds ---\" % round(time.time()-firstTime,4))#2.36245275"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--- 44.1035 seconds ---\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"du6h05eBwfVm","colab_type":"text"},"source":["**9. Create dataframe, add score and save output**"]},{"cell_type":"code","metadata":{"id":"DULEEh24PD6x","colab_type":"code","colab":{}},"source":["df = pd.DataFrame(vectors)\n","df[\"Reviewer_Score\"] = score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8WzHymPCPF7V","colab_type":"code","colab":{}},"source":["df.to_csv(\"/content/drive/My Drive/Pretrained.csv\", index=False)"],"execution_count":0,"outputs":[]}]}