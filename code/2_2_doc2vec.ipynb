{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time \n",
    "\n",
    "hotelData = pd.read_csv('../data/preprocessed/tokenTrue_remStpwrdsTrue_stemmTrue_lemmatizeFalse_nGramFalse_nGram_length2.csv')  \n",
    "review = hotelData[\"Review\"].apply(lambda row: row.strip(\"']['\").split(\"', '\"))\n",
    "score = hotelData[\"Reviewer_Score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create wordlist of all inputs togehter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "# Source: https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings/comments\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def build_vocab(sentences, verbose =  True):\n",
    "    \"\"\"\n",
    "    :param sentences: list of list of words\n",
    "    :return: dictionary of words and their count\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 515738/515738 [00:03<00:00, 164072.66it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and the keyedVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 39.6364 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.models as g\n",
    "\n",
    "firstTime = time.time()\n",
    "#documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(abstractsPro)]\n",
    "modelLNK = \"C:\\\\Users\\\\Admin\\\\Downloads\\\\enwiki_dbow\\\\doc2vec.bin\"\n",
    "\n",
    "\n",
    "#inference hyper-parameters\n",
    "start_alpha=0.01\n",
    "infer_epoch=1000\n",
    " \n",
    "#load model\n",
    "\n",
    "model = g.Doc2Vec.load(modelLNK)\n",
    "#model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "\n",
    "#embeddings_index = KeyedVectors.load_word2vec_format(modelLNK, binary=True)\n",
    "embeddings_index = model.wv\n",
    "\n",
    "\n",
    "# # Save file and load it again\n",
    "# fname = get_tmpfile(\"my_doc2vec_model\")\n",
    "\n",
    "# model.save(fname)\n",
    "# model = Doc2Vec.load(fname)  # you can continue training with the loaded model!\n",
    "# #delete traingmode (save memmory)\n",
    "# model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "print (\"--- %s seconds ---\" % round(time.time()-firstTime,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compares the word of the embedding with the words of our text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings/comments\n",
    "import operator \n",
    "\n",
    "def check_coverage(vocab,embeddings_index):\n",
    "    a = {}\n",
    "    oov = {}\n",
    "    k = 0\n",
    "    i = 0\n",
    "    for word in tqdm(vocab):\n",
    "        try:\n",
    "            a[word] = embeddings_index[word]\n",
    "            k += vocab[word]\n",
    "        except:\n",
    "\n",
    "            oov[word] = vocab[word]\n",
    "            i += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
    "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 60861/60861 [00:01<00:00, 37870.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 39.86% of vocab\n",
      "Found embeddings for  81.60% of all text\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('locat', 214788),\n",
       " ('friendli', 92033),\n",
       " ('servic', 48688),\n",
       " ('realli', 44774),\n",
       " ('restaur', 38723),\n",
       " ('everyth', 36795),\n",
       " ('recept', 32698),\n",
       " ('amaz', 22735),\n",
       " ('coffe', 22678),\n",
       " ('comfi', 22325),\n",
       " ('arriv', 20525),\n",
       " ('expens', 19143),\n",
       " ('beauti', 16928),\n",
       " ('fantast', 16779),\n",
       " ('extrem', 16120),\n",
       " ('spaciou', 16102),\n",
       " ('welcom', 15916),\n",
       " ('noisi', 15077),\n",
       " ('upgrad', 14129),\n",
       " ('peopl', 13926)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!  in the embedding:  True\n",
      "\"  in the embedding:  False\n",
      "#  in the embedding:  True\n",
      "$  in the embedding:  True\n",
      "%  in the embedding:  True\n",
      "&  in the embedding:  True\n",
      "'  in the embedding:  True\n",
      "(  in the embedding:  False\n",
      ")  in the embedding:  False\n",
      "*  in the embedding:  True\n",
      "+  in the embedding:  True\n",
      ",  in the embedding:  True\n",
      "-  in the embedding:  True\n",
      ".  in the embedding:  True\n",
      "/  in the embedding:  True\n",
      ":  in the embedding:  True\n",
      ";  in the embedding:  True\n",
      "<  in the embedding:  True\n",
      "=  in the embedding:  True\n",
      ">  in the embedding:  True\n",
      "?  in the embedding:  True\n",
      "@  in the embedding:  True\n",
      "[  in the embedding:  False\n",
      "\\  in the embedding:  True\n",
      "]  in the embedding:  False\n",
      "^  in the embedding:  True\n",
      "_  in the embedding:  True\n",
      "`  in the embedding:  True\n",
      "{  in the embedding:  False\n",
      "|  in the embedding:  True\n",
      "}  in the embedding:  False\n",
      "~  in the embedding:  True\n",
      "’  in the embedding:  False\n",
      "”  in the embedding:  False\n",
      "“  in the embedding:  False\n",
      "—  in the embedding:  False\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "punctuationList = string.punctuation \n",
    "punctuationList = punctuationList+\"’\" + \"”\" + \"“\"+\"—\"\n",
    "for punctuation in punctuationList:\n",
    "    print(punctuation, \" in the embedding: \",punctuation in embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      ",\n",
      ".\n",
      "of\n",
      "and\n",
      "in\n",
      "a\n",
      "to\n",
      "was\n",
      "''\n",
      "``\n",
      "is\n",
      "for\n",
      "-rrb-\n",
      "-lrb-\n",
      "as\n",
      "on\n",
      "with\n",
      "by\n",
      "he\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(embeddings_index.index2entity[i])\n",
    "#TODO: -LRB- and -RRB- are currently used instead of \"(\" and \")\" .... also  ” to \" .... also -- has to has a meaning (maybe a placehoder for numbers like in https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings/comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReviewSample = review.sample(n=100, random_state=1) #frac\n",
    "ScoreSample = score.sample(n=100, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 122.3167 seconds ---\n"
     ]
    }
   ],
   "source": [
    "firstTime = time.time()\n",
    "vectors = []\n",
    "# for x,y in documents:\n",
    "#     vectors.append(model.docvecs[y[0]]) \n",
    "for text in ReviewSample:\n",
    "    vectors.append(model.infer_vector(text))\n",
    "print (\"--- %s seconds ---\" % round(time.time()-firstTime,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klassification: Gehört eigentlich in ein anders Notebook, aber faul und soo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======TRAIN=========\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    vectors, ScoreSample,test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"=======TRAIN=========\")\n",
    "# display(data_train)\n",
    "# display(target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
